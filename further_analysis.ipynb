{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Imports:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (20, 8)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Definition of functions:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "outputs": [],
   "source": [
    "# search for columns_selection\n",
    "def determine_columns_sel(dataset_name):\n",
    "\n",
    "    # initialize columns_sel as list\n",
    "    columns_sel = []\n",
    "    if dataset_name == 'sepsis_cases_1':\n",
    "            columns_sel = ['Diagnose', 'mean_open_cases', 'Age', 'std_Leucocytes', 'std_CRP']#sepsis_cases_1\n",
    "    elif dataset_name == 'sepsis_cases_2':\n",
    "            columns_sel = ['Diagnose', 'mean_open_cases', 'mean_hour', 'DisfuncOrg']#sepsis_cases_2\n",
    "    elif dataset_name == 'sepsis_cases_4':\n",
    "            columns_sel = ['Diagnose', 'mean_open_cases', 'Age', 'org:group_E', 'std_CRP', 'DiagnosticECG']#sepsis_cases_4\n",
    "    elif dataset_name == 'bpic2011_f1':\n",
    "            columns_sel = ['Diagnosis Treatment Combination ID', 'mean_open_cases', 'Diagnosis', 'Activity code_376400.0']#bpic2011_f1\n",
    "    elif dataset_name == 'bpic2011_f2':\n",
    "            columns_sel = ['Diagnosis Treatment Combination ID', 'Diagnosis', 'Diagnosis code', 'mean_open_cases', 'Activity code_376400.0', 'Age', 'Producer code_CHE1']#bpic2011_f2\n",
    "    elif dataset_name == 'bpic2011_f3':\n",
    "            columns_sel = ['Diagnosis Treatment Combination ID', 'Diagnosis', 'mean_open_cases', 'Diagnosis code', 'std_event_nr', 'mean_event_nr']#bpic2011_f3\n",
    "    elif dataset_name == 'bpic2011_f4':\n",
    "            columns_sel = ['Diagnosis Treatment Combination ID', 'Treatment code']#bpic2011_f4\n",
    "    elif dataset_name == 'bpic2012_accepted':\n",
    "            columns_sel = ['AMOUNT_REQ', 'Activity_O_SENT_BACK-COMPLETE', 'Activity_W_Valideren aanvraag-SCHEDULE', 'Activity_W_Valideren aanvraag-START']#bpic2012_accepted\n",
    "    elif dataset_name == 'bpic2012_declined':\n",
    "            columns_sel = ['AMOUNT_REQ', 'Activity_A_PARTLYSUBMITTED-COMPLETE', 'Activity_A_PREACCEPTED-COMPLETE', 'Activity_A_DECLINED-COMPLETE', 'Activity_W_Completeren aanvraag-SCHEDULE', 'mean_open_cases'] #bpic2012_declined\n",
    "    elif dataset_name == 'bpic2012_cancelled':\n",
    "            columns_sel = ['Activity_O_SENT_BACK-COMPLETE', 'Activity_W_Valideren aanvraag-SCHEDULE', 'Activity_W_Valideren aanvraag-START', 'AMOUNT_REQ', 'Activity_W_Valideren aanvraag-COMPLETE', 'Activity_A_CANCELLED-COMPLETE']#bpic2012_cancelled\n",
    "    elif dataset_name == 'production':\n",
    "            columns_sel = ['Work_Order_Qty', 'Activity_Turning & Milling - Machine 4', 'Resource_ID0998', 'Resource_ID4794', 'Resource.1_Machine 4 - Turning & Milling']#production\n",
    "    return columns_sel"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "outputs": [],
   "source": [
    "# collection of model and evaluation with test-set\n",
    "def creation_and_prediction(dataset_name, columns_sel):\n",
    "\n",
    "    # create model from train_anfis.py\n",
    "    model = torch.load('models_lj/model_' + dataset_name + '.h5')\n",
    "    # read in data from the test-set and separate into features and classification\n",
    "    df_test = pd.read_csv(\"dataset/\" + dataset_name + \"/\" + dataset_name + '_test.csv', header=0, sep=',')\n",
    "    df_features = df_test[columns_sel]\n",
    "    df_targets = df_test[['Classification']]\n",
    "    # create torch array from features\n",
    "    conv_test = torch.tensor(df_features.values, dtype=torch.float)\n",
    "    # enable evaluation mode\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # predict outcome of each feature vector and split into prediction and certainty\n",
    "        pred = model(torch.Tensor(conv_test))\n",
    "        pred = torch.max(pred, 1)\n",
    "    # we can call the outcome of the model: certainty since it is a summation of gaussian outcomes. This is why this NN is also refered to s XAI... certainty is already part of the outcome.\n",
    "    df_targets = df_targets.assign(model_classification = pred.indices.detach().numpy(), model_certainty = pred.values.detach().numpy())\n",
    "    return df_features, df_targets"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "outputs": [],
   "source": [
    "# creation of certainty-histograms with 50 bins. Distinguishment between false and correct cases\n",
    "def histplot_model_certainty(df_features, df_targets, dataset_name):\n",
    "\n",
    "    # check if classification of model is similar to the true classification of the feature vector\n",
    "    false_class_df = df_features.loc[df_targets['Classification'] != df_targets['model_classification']]\n",
    "    false_class_df['model_certainty'] = df_targets['model_certainty'].iloc[false_class_df.index]\n",
    "    # create histogram for analysis purposes\n",
    "    histplot_binning = np.linspace(0, df_targets['model_certainty'].max(), 50)\n",
    "    # create visualization\n",
    "    fig, axs = plt.subplots(1,1)\n",
    "    sn.histplot(data=df_targets, x='model_certainty', bins=histplot_binning, color='b', label='all')\n",
    "    sn.histplot(data=false_class_df, x='model_certainty', bins=histplot_binning, color='r', label='false')\n",
    "    axs.set_title(f'Model certainty comparison of all and false classifications of the test-set of {dataset_name}', fontsize=20)\n",
    "    axs.legend(fontsize=15)\n",
    "    axs.set_xlabel('model_certainty', fontsize=15)\n",
    "    axs.set_ylabel('Count', fontsize=15)\n",
    "    axs.tick_params(labelsize=12)\n",
    "    #plt.savefig('results/further_analysis/'+dataset_name+'_hist-certainty.png')\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "outputs": [],
   "source": [
    "# binning of ids that were assigned faulty corresponding to their prediction certainty\n",
    "def binning_of_ids(df_targets, bins_numb=10):\n",
    "\n",
    "    # assign bin labels to predictions that were faulty. I.e. you can understand the bin labels as level of falseness.\n",
    "    false_class_df = df_targets.loc[df_targets['Classification'] != df_targets['model_classification']]\n",
    "    max = false_class_df['model_certainty'].max()\n",
    "    bins = np.linspace(0, max, bins_numb+1)\n",
    "    false_class_df = false_class_df.assign(certainty_bins = pd.cut(false_class_df['model_certainty'], bins, labels=range(1,bins_numb+1)))\n",
    "    return false_class_df, max"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "outputs": [],
   "source": [
    "# from the previous binning we can check which cases were bad (certainty_bins > 5). Let's check them...\n",
    "def get_bad_case_ids(df_targets, dataset_name):\n",
    "\n",
    "    len_df = pd.read_csv(f'dataset/{dataset_name}/len_test{dataset_name}.csv')\n",
    "    indices =  df_targets.loc[df_targets['certainty_bins']>5].index.tolist()\n",
    "    case_ids = list(set(len_df.loc[indices, 'CaseID'].unique().astype(str)))\n",
    "    return case_ids"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Main:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "outputs": [],
   "source": [
    "bad_case_ids = dict()\n",
    "bad_case_ids['__dataset_name'] = '__bad_case_ids'\n",
    "\n",
    "for name in ['sepsis_cases_2', 'production', 'bpic2011_f3']:\n",
    "    _, df_targ = creation_and_prediction(name, determine_columns_sel(name))\n",
    "    fc_df, max = binning_of_ids(df_targ)\n",
    "    bad_case_ids[name] = get_bad_case_ids(fc_df, name)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "outputs": [],
   "source": [
    "with open(\"results/further_analysis/bad_case_ids.json\", \"w\") as outfile:\n",
    "    outfile.write(json.dumps(bad_case_ids, sort_keys=True))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "outputs": [
    {
     "data": {
      "text/plain": "\"sn.histplot(data=fc_df.loc[fc_df['certainty_bins']<=5], x='certainty_bins', color='blue')\\nsn.histplot(data=fc_df.loc[fc_df['certainty_bins']> 5], x='certainty_bins', color='red')\\nplt.suptitle(f'Histogram of model_certainty for false classifications in '{name}'-dataset (max_model_certainty = {max:.2f})', fontsize=20)\\nplt.xlabel('certainty_bins', fontsize=15)\\nplt.ylabel('Count', fontsize=15)\\nplt.tick_params(labelsize=12)\\n#plt.savefig('results/further_analysis/'+name+'_hist-certainty-false_class.png')\\nplt.show()\""
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''sn.histplot(data=fc_df.loc[fc_df['certainty_bins']<=5], x='certainty_bins', color='blue')\n",
    "sn.histplot(data=fc_df.loc[fc_df['certainty_bins']> 5], x='certainty_bins', color='red')\n",
    "plt.suptitle(f'Histogram of model_certainty for false classifications in \\'{name}\\'-dataset (max_model_certainty = {max:.2f})', fontsize=20)\n",
    "plt.xlabel('certainty_bins', fontsize=15)\n",
    "plt.ylabel('Count', fontsize=15)\n",
    "plt.tick_params(labelsize=12)\n",
    "#plt.savefig('results/further_analysis/'+name+'_hist-certainty-false_class.png')\n",
    "plt.show()'''"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
